{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777b6dde",
   "metadata": {},
   "source": [
    "# Write Julia-C++ wrapper for ghostbasil\n",
    "\n",
    "`ml cmake/3.11.1 gcc/7.1.0 julia/1.8.4 eigen/3.4.0`\n",
    "\n",
    "1. We will be using [CxxWrap.jl](https://github.com/JuliaInterop/CxxWrap.jl) to call C++ code within Julia. \n",
    "2. We need a working `libcxxwrap_julia_jll.jl`. I simply installed the jll package\n",
    "```\n",
    "add https://github.com/barche/libcxxwrap_julia_jll.jl.git\n",
    "```\n",
    "3. Once it's done, we need CMake to discover `libcxxwrap-julia`. This can be done by adding `-DCMAKE_PREFIX_PATH=/path/to/libcxxwrap-julia-prefix` to the `cmake` command where `/path/to/libcxxwrap-julia-prefix` is obtained from\n",
    "```\n",
    "julia> using CxxWrap\n",
    "julia> CxxWrap.prefix_path()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49abb6f",
   "metadata": {},
   "source": [
    "## Hello world example\n",
    "\n",
    "Here is my `hello.cpp` file:\n",
    "```cpp\n",
    "#include <string>\n",
    "#include \"jlcxx/jlcxx.hpp\"\n",
    "\n",
    "std::string greet()\n",
    "{\n",
    "   return \"hello, world\";\n",
    "}\n",
    "\n",
    "JLCXX_MODULE define_julia_module(jlcxx::Module& mod)\n",
    "{\n",
    "  mod.method(\"greet\", &greet);\n",
    "}\n",
    "```\n",
    "\n",
    "And here is the `CMakeLists.txt` file:\n",
    "\n",
    "```cmake\n",
    "project(HelloWorld)\n",
    "\n",
    "cmake_minimum_required(VERSION 3.5)\n",
    "set(CMAKE_MACOSX_RPATH 1)\n",
    "set(CMAKE_LIBRARY_OUTPUT_DIRECTORY \"${CMAKE_BINARY_DIR}/lib\")\n",
    "\n",
    "find_package(JlCxx)\n",
    "get_target_property(JlCxx_location JlCxx::cxxwrap_julia LOCATION)\n",
    "get_filename_component(JlCxx_location ${JlCxx_location} DIRECTORY)\n",
    "set(CMAKE_INSTALL_RPATH \"${CMAKE_INSTALL_PREFIX}/lib;${JlCxx_location}\")\n",
    "\n",
    "message(STATUS \"Found JlCxx at ${JlCxx_location}\")\n",
    "\n",
    "add_library(hello SHARED hello.cpp)\n",
    "\n",
    "target_link_libraries(hello JlCxx::cxxwrap_julia)\n",
    "\n",
    "install(TARGETS\n",
    "  hello\n",
    "LIBRARY DESTINATION lib\n",
    "ARCHIVE DESTINATION lib\n",
    "RUNTIME DESTINATION lib)\n",
    "```\n",
    "\n",
    "Given these 2 files, we build the shared library (`.io`) file as\n",
    "```\n",
    "mkdir build && cd build\n",
    "cmake \\\n",
    "    -DCMAKE_BUILD_TYPE=Release \\\n",
    "    -DCMAKE_PREFIX_PATH=/home/groups/sabatti/.julia/artifacts/d25a86126e4d79572040fbf3f1fcda158a703a4a \\\n",
    "    ../\n",
    "cmake --build . --config Release\n",
    "```\n",
    "Finally, we can call hello world in Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0606c0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello, world\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the module and generate the functions\n",
    "module CppHello\n",
    "    using CxxWrap\n",
    "    @wrapmodule(() -> \"/home/users/bbchu/ghostbasilwrap/build/lib/libhello\")\n",
    "\n",
    "    function __init__()\n",
    "        @initcxx\n",
    "    end\n",
    "end\n",
    "\n",
    "# Call greet and show the result\n",
    "CppHello.greet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00be426",
   "metadata": {},
   "source": [
    "## Pass matrix from Julia into C++, calculate the sum, and return answer\n",
    "\n",
    "First create `sumarray.cpp`\n",
    "\n",
    "```cpp\n",
    "#include \"jlcxx/jlcxx.hpp\"\n",
    "#include <vector>\n",
    "#include <iostream>\n",
    "using namespace std;\n",
    "\n",
    "double cpp_mat_sum(jlcxx::ArrayRef<double, 2> x) {\n",
    "    cout << &x[0] << endl; // print memory address of x\n",
    "    cout << x.size() << endl; // print length of x\n",
    "    double total = 0;\n",
    "    for(auto xij : x) {\n",
    "        total += xij;\n",
    "    }\n",
    "    return total;\n",
    "}\n",
    "\n",
    "std::vector<double> get_custom_return_vec(jlcxx::ArrayRef<double, 2> x) {\n",
    "    std::vector<double> result;\n",
    "    result.push_back(cpp_mat_sum(x));\n",
    "    result.push_back(x[0]);\n",
    "    result.push_back(x[1]);\n",
    "    return result;\n",
    "}\n",
    "\n",
    "JLCXX_MODULE define_julia_module(jlcxx::Module& mod)\n",
    "{\n",
    "    mod.method(\"cpp_mat_sum\", &cpp_mat_sum);\n",
    "    mod.method(\"get_custom_return_vec\", &get_custom_return_vec);\n",
    "}\n",
    "```\n",
    "\n",
    "Then create `CMakeLists.txt` file\n",
    "\n",
    "```cmake\n",
    "project(Examples)\n",
    "\n",
    "cmake_minimum_required(VERSION 3.5)\n",
    "set(CMAKE_MACOSX_RPATH 1)\n",
    "set(CMAKE_LIBRARY_OUTPUT_DIRECTORY \"${CMAKE_BINARY_DIR}/lib\")\n",
    "\n",
    "find_package(JlCxx)\n",
    "get_target_property(JlCxx_location JlCxx::cxxwrap_julia LOCATION)\n",
    "get_filename_component(JlCxx_location ${JlCxx_location} DIRECTORY)\n",
    "set(CMAKE_INSTALL_RPATH \"${CMAKE_INSTALL_PREFIX}/lib;${JlCxx_location}\")\n",
    "\n",
    "message(STATUS \"Found JlCxx at ${JlCxx_location}\")\n",
    "\n",
    "add_library(hello SHARED hello.cpp)\n",
    "add_library(sumarray SHARED sumarray.cpp)\n",
    "\n",
    "target_link_libraries(hello JlCxx::cxxwrap_julia)\n",
    "target_link_libraries(sumarray JlCxx::cxxwrap_julia)\n",
    "\n",
    "install(TARGETS\n",
    "  hello sumarray \n",
    "LIBRARY DESTINATION lib\n",
    "ARCHIVE DESTINATION lib\n",
    "RUNTIME DESTINATION lib)\n",
    "```\n",
    "Given these 2 files, we build the shared library (`.io`) file as\n",
    "```\n",
    "mkdir build && cd build\n",
    "cmake \\\n",
    "    -DCMAKE_BUILD_TYPE=Release \\\n",
    "    -DCMAKE_PREFIX_PATH=/home/groups/sabatti/.julia/artifacts/d25a86126e4d79572040fbf3f1fcda158a703a4a \\\n",
    "    ../\n",
    "cmake --build . --config Release\n",
    "```\n",
    "Finally, we can call both `hello` and `sumarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82eb5364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello, world\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module CppHello\n",
    "    using CxxWrap\n",
    "    @wrapmodule(() -> \"/home/users/bbchu/ghostbasilwrap/build/lib/libhello\")\n",
    "\n",
    "    function __init__()\n",
    "        @initcxx\n",
    "    end\n",
    "end\n",
    "\n",
    "# Call greet and show the result\n",
    "CppHello.greet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b2568d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x7fbaf050b040\n",
      "100000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-9379.300114470054"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module CppSumArray\n",
    "    using CxxWrap\n",
    "    @wrapmodule(() -> \"/home/users/bbchu/ghostbasilwrap/build/lib/libsumarray\")\n",
    "\n",
    "    function __init__()\n",
    "        @initcxx\n",
    "    end\n",
    "end\n",
    "\n",
    "x = randn(10000, 10000)\n",
    "CppSumArray.cpp_mat_sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee82f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9379.300114469586"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4cc0607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ptr{Float64} @0x00007fbaf050b040"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9283dabd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x7fbaf050b040\n",
      "100000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element CxxWrap.StdLib.StdVectorAllocated{Float64}:\n",
       " -9379.300114470054\n",
       "    -0.4856036463361442\n",
       "     0.6013781816541801"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CppSumArray.get_custom_return_vec(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499d73a8",
   "metadata": {},
   "source": [
    "## Pass matrix from Julia into C++ as a Eigen matrix\n",
    "\n",
    "+ [this tutorial](https://www.youtube.com/watch?v=VoXmXtqLhdo&ab_channel=TheJuliaProgrammingLanguage) which wraps the Eigen library (starging at 1:13:00) was especially helpful.\n",
    "\n",
    "\n",
    "1. First create `eigen_matrix.cpp`\n",
    "\n",
    "```cpp\n",
    "#include <jlcxx/jlcxx.hpp>\n",
    "#include <jlcxx/stl.hpp>\n",
    "#include <Eigen/Dense>\n",
    "\n",
    "JLCXX_MODULE define_julia_module(jlcxx::Module& mod)\n",
    "{\n",
    "  mod.add_type<Eigen::MatrixXd>(\"MatrixXd\", jlcxx::julia_type(\"AbstractMatrixXd\"))\n",
    "    .constructor<int_t, int_t>()\n",
    "    .method(\"cols\", &Eigen::MatrixXd::cols)\n",
    "    .method(\"rows\", &Eigen::MatrixXd::rows)\n",
    "    .method(\"norm\", &Eigen::MatrixXd::norm)\n",
    "    .method(\"setConstant\", static_cast<Eigen::MatrixXd& (Eigen::MatrixXd::*)(const double&)>(&Eigen::MatrixXd::setConstant))\n",
    "  ;\n",
    "\n",
    "  mod.set_override_module(jl_base_module);\n",
    "  mod.method(\"getindex\", [](const Eigen::MatrixXd& m, int_t i, int_t j) { return m(i-1, j-1); });\n",
    "  mod.method(\"setindex!\", [](Eigen::MatrixXd& m, double value, int_t i, int_t j) { m(i-1, j-1) = value; });\n",
    "  mod.unset_override_module();\n",
    "}\n",
    "```\n",
    "\n",
    "2. Then create `CMakeLists.txt` file\n",
    "\n",
    "```cmake\n",
    "project(JlEigen)\n",
    "\n",
    "cmake_minimum_required(VERSION 3.5)\n",
    "set(CMAKE_MACOSX_RPATH 1)\n",
    "set(CMAKE_LIBRARY_OUTPUT_DIRECTORY \"${CMAKE_BINARY_DIR}/lib\")\n",
    "\n",
    "find_package(Eigen3 3.3 REQUIRED NO_MODULE)\n",
    "find_package(JlCxx)\n",
    "get_target_property(JlCxx_location JlCxx::cxxwrap_julia LOCATION)\n",
    "get_filename_component(JlCxx_location ${JlCxx_location} DIRECTORY)\n",
    "set(CMAKE_INSTALL_RPATH \"${CMAKE_INSTALL_PREFIX}/lib;${JlCxx_location}\")\n",
    "\n",
    "message(STATUS \"Found JlCxx at ${JlCxx_location}\")\n",
    "\n",
    "add_library(eigen_matrix SHARED eigen_matrix.cpp)\n",
    "target_link_libraries(eigen_matrix JlCxx::cxxwrap_julia Eigen3::Eigen)\n",
    "\n",
    "install(TARGETS\n",
    "  eigen_matrix \n",
    "LIBRARY DESTINATION lib\n",
    "ARCHIVE DESTINATION lib\n",
    "RUNTIME DESTINATION lib)\n",
    "```\n",
    "3. Build the shared library (`.io`) file as\n",
    "```\n",
    "mkdir build && cd build\n",
    "cmake \\\n",
    "    -DCMAKE_BUILD_TYPE=Release \\\n",
    "    -DCMAKE_PREFIX_PATH=/home/groups/sabatti/.julia/artifacts/d25a86126e4d79572040fbf3f1fcda158a703a4a \\\n",
    "    /home/users/bbchu/ghostbasilwrap \\\n",
    "    -DEigen3_DIR=/share/software/user/open/eigen/3.4.0/share/eigen3/cmake \\\n",
    "    ../\n",
    "cmake --build . --config Release\n",
    "```\n",
    "4. Finally, we call `eigen_matrix` in Julia as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe0517b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.CppEigenMatrix"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module CppEigenMatrix\n",
    "    using CxxWrap\n",
    "    abstract type AbstractMatrixXd <: AbstractMatrix{Float64} end\n",
    "\n",
    "    @wrapmodule(() -> \"/home/users/bbchu/ghostbasilwrap/build/lib/libeigen_matrix\")\n",
    "\n",
    "    function __init__()\n",
    "        @initcxx\n",
    "    end\n",
    "\n",
    "    Base.size(m::MatrixXd) = (rows(m),cols(m))\n",
    "    Base.IndexStyle(::Type{<:MatrixXd})=IndexCartesian()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21951736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Main.CppEigenMatrix.MatrixXdAllocated:\n",
       " 1.0  2.0\n",
       " 3.0  4.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = CppEigenMatrix.MatrixXd(2, 2)\n",
    "m[1, 1] = 1\n",
    "m[1, 2] = 2\n",
    "m[2, 1] = 3\n",
    "m[2, 2] = 4\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f6bad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Main.CppEigenMatrix.MatrixXdAllocated:\n",
       " 0.117769  0.400588\n",
       " 0.581882  0.883709"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m .= rand(2, 2)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed6ec60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Main.CppEigenMatrix.MatrixXdAllocated}:\n",
       " [6.93878695892835e-310 3.8126295e-316; 4.35062666e-316 4.14520603e-316]\n",
       " [6.93878695892993e-310 1.402447575785111e-307 3.37845646e-316; 4.25517397e-316 4.2538981e-316 4.06314054e-316; 2.2089196780820652e161 1.63e-322 3.95e-322]\n",
       " [6.9387869589331e-310 0.0 1.32543386e-316 0.0; 4.12702283e-316 0.0 0.0 0.0; 4.25149615e-316 4.09589393e-316 4.246258147e-314 4.37705957e-316; 4.07452855e-316 4.07452855e-316 0.0 2.121995791e-314]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = CppEigenMatrix.MatrixXd(2, 2)\n",
    "m2 = CppEigenMatrix.MatrixXd(3, 3)\n",
    "m3 = CppEigenMatrix.MatrixXd(4, 4)\n",
    "blocks = [m1, m2, m3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9420e219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector{MatrixXdAllocated}\u001b[90m (alias for \u001b[39m\u001b[90mArray{Main.CppEigenMatrix.MatrixXdAllocated, 1}\u001b[39m\u001b[90m)\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a5dd18",
   "metadata": {},
   "source": [
    "## \"Template types\": pass matrix from Julia into C++ as a Eigen matrix\n",
    "\n",
    "1. First create `eigen_matrix.cpp`\n",
    "\n",
    "```cpp\n",
    "#include <jlcxx/jlcxx.hpp>\n",
    "#include <jlcxx/stl.hpp>\n",
    "#include <Eigen/Dense>\n",
    "\n",
    "namespace jleigen\n",
    "{\n",
    "  struct WrapMatrix\n",
    "  {\n",
    "    template<typename TypeWrapperT>\n",
    "    void operator()(TypeWrapperT&& wrapped)\n",
    "    {\n",
    "      using WrappedT = typename TypeWrapperT::type; // WrappedT is basically Eigen::MatrixXd and its relatives\n",
    "      using ScalarT = typename WrappedT::Scalar;\n",
    "      wrapped.template constructor<Eigen::Index, Eigen::Index>();\n",
    "      wrapped.method(\"cols\", &WrappedT::cols);\n",
    "      wrapped.method(\"rows\", &WrappedT::rows);\n",
    "      wrapped.method(\"norm\", &WrappedT::norm);\n",
    "      wrapped.method(\"setConstant\", static_cast<WrappedT& (WrappedT::*)(const ScalarT&)>(&WrappedT::setConstant));\n",
    " \n",
    "      wrapped.module().set_override_module(jl_base_module);\n",
    "      wrapped.module().method(\"getindex\", [](const WrappedT& m, int_t i, int_t j) { return m(i-1,j-1); });\n",
    "      wrapped.module().method(\"setindex!\", [](WrappedT& m, ScalarT value, int_t i, int_t j) { m(i-1,j-1) = value; });\n",
    "      wrapped.module().unset_override_module();\n",
    " \n",
    "      wrapped.module().method(\"toString\", [] (const WrappedT& m)\n",
    "      {\n",
    "        std::stringstream stream;\n",
    "        stream << m;\n",
    "        return stream.str();\n",
    "      });\n",
    "    }\n",
    "  };\n",
    "}\n",
    " \n",
    "namespace jlcxx\n",
    "{\n",
    "  template<typename T>\n",
    "  struct BuildParameterList<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n",
    "  {\n",
    "    typedef ParameterList<T> type;\n",
    "  };\n",
    "}\n",
    " \n",
    "JLCXX_MODULE define_julia_module(jlcxx::Module& mod)\n",
    "{\n",
    "  using jlcxx::Parametric;\n",
    "  using jlcxx::TypeVar;\n",
    "  mod.add_type<Parametric<TypeVar<1>>>(\"Matrix\", jlcxx::julia_type(\"AbstractMatrix\"))\n",
    "    .apply<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>, Eigen::Matrix<float, Eigen::Dynamic, Eigen::Dynamic>>(jleigen::WrapMatrix());\n",
    "}\n",
    "```\n",
    "\n",
    "2. Then create `CMakeLists.txt` file\n",
    "\n",
    "```cmake\n",
    "project(JlEigen)\n",
    "\n",
    "cmake_minimum_required(VERSION 3.5)\n",
    "set(CMAKE_MACOSX_RPATH 1)\n",
    "set(CMAKE_LIBRARY_OUTPUT_DIRECTORY \"${CMAKE_BINARY_DIR}/lib\")\n",
    "\n",
    "find_package(Eigen3 3.3 REQUIRED NO_MODULE)\n",
    "find_package(JlCxx)\n",
    "get_target_property(JlCxx_location JlCxx::cxxwrap_julia LOCATION)\n",
    "get_filename_component(JlCxx_location ${JlCxx_location} DIRECTORY)\n",
    "set(CMAKE_INSTALL_RPATH \"${CMAKE_INSTALL_PREFIX}/lib;${JlCxx_location}\")\n",
    "\n",
    "message(STATUS \"Found JlCxx at ${JlCxx_location}\")\n",
    "\n",
    "add_library(eigen_matrix SHARED eigen_matrix.cpp)\n",
    "target_link_libraries(eigen_matrix JlCxx::cxxwrap_julia Eigen3::Eigen)\n",
    "\n",
    "install(TARGETS\n",
    "  eigen_matrix \n",
    "LIBRARY DESTINATION lib\n",
    "ARCHIVE DESTINATION lib\n",
    "RUNTIME DESTINATION lib)\n",
    "```\n",
    "3. Build the shared library (`.io`) file as\n",
    "```\n",
    "mkdir build && cd build\n",
    "cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH=/home/groups/sabatti/.julia/dev/libcxxwrap_julia_jll/override /home/users/bbchu/ghostbasilwrap -DEigen3_DIR=/share/software/user/open/eigen/3.4.0/share/eigen3/cmake\n",
    "cmake --build . --config Release\n",
    "```\n",
    "4. Finally, we call `eigen_matrix` in Julia as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e66ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.CppEigenMatrix"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module CppEigenMatrix\n",
    "    using CxxWrap\n",
    "\n",
    "    @wrapmodule(\"/home/users/bbchu/ghostbasilwrap/build/lib/libeigen_matrix\")\n",
    "\n",
    "    function __init__()\n",
    "        @initcxx\n",
    "    end\n",
    "\n",
    "    Base.size(m::Matrix) = (rows(m), cols(m))\n",
    "    Base.IndexStyle(::Type{<:Matrix})=IndexCartesian()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b16ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Main.CppEigenMatrix.MatrixAllocated{Float64}:\n",
       " 3.37652e-316  5.16164e160\n",
       " 0.0           3.37652e-316"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = CppEigenMatrix.Matrix{Float64}(2, 2)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db448a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Main.CppEigenMatrix.MatrixAllocated{Float32}:\n",
       " 6.31802f-37  1.89395f34\n",
       " 0.0          4.34382f-5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = CppEigenMatrix.Matrix{Float32}(2, 2)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf18521",
   "metadata": {},
   "source": [
    "# Wrap ghostbasil's `BlockMatrix` class\n",
    "\n",
    "+ We will be writing Julia bindings in `/home/users/bbchu/ghostbasil`\n",
    "+ [this tutorial](https://www.youtube.com/watch?v=VoXmXtqLhdo&ab_channel=TheJuliaProgrammingLanguage) which wraps the Eigen library (starging at 1:13:00) was especially helpful.\n",
    "\n",
    "\n",
    "### 1. Create `/home/users/bbchu/ghostbasil/julia/ghostbasil_wrap.cpp`\n",
    "\n",
    "```cpp\n",
    "#include \"jlcxx/jlcxx.hpp\"\n",
    "#include \"jlcxx/stl.hpp\"\n",
    "#include \"ghostbasil/matrix/block_matrix.hpp\"\n",
    "#include \"ghostbasil/matrix/block_group_ghost_matrix.hpp\"\n",
    "\n",
    "class OneBlockMatrixWrap\n",
    "{\n",
    "    jlcxx::ArrayRef<double, 2> orig_mat_; // original matrix\n",
    "    Eigen::MatrixXd eigen_mat_; // convert to Eigen::MatrixXd\n",
    "    ghostbasil::BlockMatrix<Eigen::Map<Eigen::MatrixXd>> block_mat_;\n",
    "\n",
    "    static auto init_eigen_mat(jlcxx::ArrayRef<double, 2> mat, int_t rows, int_t cols) {\n",
    "        Eigen::MatrixXd eigen_mat_(rows, cols);\n",
    "        size_t k = 0;\n",
    "        for (size_t i = 0; i < cols; i++) {\n",
    "            for (size_t j = 0; j < rows; j++) {\n",
    "                eigen_mat_(j, i) = mat[k++];\n",
    "            }\n",
    "        }\n",
    "        return eigen_mat_;\n",
    "    }\n",
    "\n",
    "    static auto init_mat_list(Eigen::MatrixXd mat) {\n",
    "        std::vector<Eigen::Map<Eigen::MatrixXd>> mat_list_;\n",
    "        mat_list_.push_back(Eigen::Map<Eigen::MatrixXd>(mat.data(), 1, 1));\n",
    "        return mat_list_;\n",
    "    }\n",
    "\n",
    "public: \n",
    "    OneBlockMatrixWrap(jlcxx::ArrayRef<double, 2> mat, int_t rows, int_t cols)\n",
    "        : orig_mat_(mat),\n",
    "        eigen_mat_(init_eigen_mat(mat, rows, cols)),\n",
    "        block_mat_(init_mat_list(eigen_mat_))\n",
    "    {\n",
    "        std::cout << \"row: \" << rows << '\\n';\n",
    "        std::cout << \"col: \" << cols << '\\n';\n",
    "        std::cout << eigen_mat_ << std::endl;\n",
    "    }\n",
    "};\n",
    "\n",
    "JLCXX_MODULE define_julia_module(jlcxx::Module& mod)\n",
    "{\n",
    "    mod.add_type<OneBlockMatrixWrap>(\"OneBlockMatrix\")\n",
    "        .constructor<jlcxx::ArrayRef<double, 2>, int_t, int_t>()\n",
    "        ;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "### 2: Create `/home/users/bbchu/ghostbasil/julia/CMakeLists.txt`:\n",
    "\n",
    "```cmake\n",
    "project(ghostbasil)\n",
    "\n",
    "cmake_minimum_required(VERSION 3.5)\n",
    "set(CMAKE_MACOSX_RPATH 1)\n",
    "set(CMAKE_LIBRARY_OUTPUT_DIRECTORY \"${CMAKE_BINARY_DIR}/lib\")\n",
    "\n",
    "find_package(JlCxx REQUIRED)\n",
    "find_package(Eigen3 3.3 REQUIRED NO_MODULE)\n",
    "include_directories(${CMAKE_CURRENT_SOURCE_DIR}/../ghostbasil/include)\n",
    "\n",
    "add_library(ghostbasil_wrap SHARED ghostbasil_wrap.cpp)\n",
    "target_link_libraries(ghostbasil_wrap JlCxx::cxxwrap_julia Eigen3::Eigen)\n",
    "install(TARGETS ghostbasil_wrap\n",
    "  LIBRARY DESTINATION lib\n",
    "  ARCHIVE DESTINATION lib\n",
    "  RUNTIME DESTINATION lib)\n",
    "```\n",
    "\n",
    "### 3. Build the shared library (`.io`) file at `/home/users/bbchu/ghostbasil/julia/build`\n",
    "```\n",
    "mkdir build && cd build\n",
    "cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH=/home/groups/sabatti/.julia/dev/libcxxwrap_julia_jll/override -DEigen3_DIR=/share/software/user/open/eigen/3.4.0/share/eigen3/cmake /home/users/bbchu/ghostbasil/julia\n",
    "cmake --build . --config Release\n",
    "```\n",
    "### 4. Call from Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518da963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.CppEigenMatrix"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module ghostbasil\n",
    "    using CxxWrap\n",
    "\n",
    "    @wrapmodule(\"/home/users/bbchu/ghostbasil/julia/build/lib/libghostbasil_wrap\")\n",
    "\n",
    "    function __init__()\n",
    "        @initcxx\n",
    "    end\n",
    "end\n",
    "\n",
    "module CppEigenMatrix\n",
    "    using CxxWrap\n",
    "\n",
    "    @wrapmodule(\"/home/users/bbchu/ghostbasilwrap/build/lib/libeigen_matrix\")\n",
    "\n",
    "    function __init__()\n",
    "        @initcxx\n",
    "    end\n",
    "\n",
    "    Base.size(m::Matrix) = (rows(m), cols(m))\n",
    "    Base.IndexStyle(::Type{<:Matrix})=IndexCartesian()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb270e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Main.CppEigenMatrix.MatrixAllocated{Float64}:\n",
       " 3.28014e-316  5.16164e160\n",
       " 0.0           3.28014e-316"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = CppEigenMatrix.Matrix{Float64}(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f706580e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Main.CppEigenMatrix.MatrixAllocated{Float64}}:\n",
       " [3.80498215e-316 5.483607035636684e247; 0.0 3.80498294e-316]\n",
       " [6.9128624369722e-310 5.9596773034521166e228 3.27782833e-316; 4.0467652e-316 1.76790384e-316 3.1870475e-316; 1.2774512412801808e238 1.63e-322 3.95e-322]\n",
       " [6.91286243697536e-310 1.7692483e-316 3.60302155e-316 0.0; 4.00469297e-316 2.1219957914e-313 4.2439915824e-314 0.0; 1.7689631e-316 2.97079410794e-313 1.7692483e-316 4.901812848809653e-24; 1.76896627e-316 3.81959242453e-313 8.2757835865e-313 3.985066447142008e-58]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = CppEigenMatrix.Matrix{Float64}(2, 2)\n",
    "m2 = CppEigenMatrix.Matrix{Float64}(3, 3)\n",
    "m3 = CppEigenMatrix.Matrix{Float64}(4, 4)\n",
    "blocks = [m1, m2, m3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed223b7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: n not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: n not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[4]:3"
     ]
    }
   ],
   "source": [
    "p = 5\n",
    "mat = rand(p, p)\n",
    "Si_scaled = ghostbasil.OneBlockMatrix(mat, n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3fe4932",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: BlockGroupGhostMatrix not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: BlockGroupGhostMatrix not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[5]:3"
     ]
    }
   ],
   "source": [
    "m = 5\n",
    "Ci = rand(p, p)\n",
    "Bi = BlockGroupGhostMatrix(Ci, Si_scaled, m+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6424e8",
   "metadata": {},
   "source": [
    "# Wrap ghostbasil's `ghostbasil` function\n",
    "\n",
    "1. In our [code](https://github.com/biona001/GhostKnockoffGWAS/blob/main/src/ghostbasil_parallel.jl#L209C1-L211C69), we need to call `ghostbasil(A, r)` where `A` is a `BlockGroupGhostMatrix`.\n",
    "2. The `BlockGroupGhostMatrix` class essentially requires a regular matrix and a `BlockMatrix`. We will pass these matrices directly into C++ and try to internally call the ghostbasil function from within C++. \n",
    "\n",
    "### 1. Create `/home/users/bbchu/ghostbasil/julia/ghostbasil_wrap.cpp`\n",
    "\n",
    "```cpp\n",
    "#include \"jlcxx/jlcxx.hpp\"\n",
    "#include \"jlcxx/stl.hpp\"\n",
    "#include \"ghostbasil/optimization/basil.hpp\"\n",
    "#include \"ghostbasil/matrix/block_matrix.hpp\"\n",
    "#include \"ghostbasil/matrix/block_group_ghost_matrix.hpp\"\n",
    "\n",
    "static auto init_eigen_vec(jlcxx::ArrayRef<double, 1> vec) {\n",
    "    Eigen::VectorXd eigen_vec(vec.size());\n",
    "    for (size_t i = 0; i < vec.size(); i++) {\n",
    "        eigen_vec(i) = vec[i];\n",
    "    }\n",
    "    return eigen_vec;\n",
    "}\n",
    "\n",
    "static auto init_eigen_mat(jlcxx::ArrayRef<double, 2> mat, int_t rows, int_t cols) {\n",
    "    Eigen::MatrixXd eigen_mat_(rows, cols);\n",
    "    size_t k = 0;\n",
    "    for (size_t i = 0; i < cols; i++) {\n",
    "        for (size_t j = 0; j < rows; j++) {\n",
    "            eigen_mat_(j, i) = mat[k++];\n",
    "        }\n",
    "    }\n",
    "    return eigen_mat_;\n",
    "}\n",
    "\n",
    "// this is BlockMatrix type in ghostbasil but only accepts 1 (dense) block\n",
    "class OneBlockMatrixWrap\n",
    "{\n",
    "    jlcxx::ArrayRef<double, 2> orig_mat_;\n",
    "    Eigen::MatrixXd eigen_mat_;\n",
    "    std::vector<Eigen::Map<Eigen::MatrixXd>> mat_list_;\n",
    "    ghostbasil::BlockMatrix<Eigen::Map<Eigen::MatrixXd>> block_mat_;\n",
    "    const Eigen::Array<size_t, 2, 1> dim_;\n",
    "\n",
    "    static auto init_mat_list(Eigen::MatrixXd mat, int_t rows, int_t cols) {\n",
    "        std::vector<Eigen::Map<Eigen::MatrixXd>> mat_list_;\n",
    "        mat_list_.emplace_back(Eigen::Map<Eigen::MatrixXd>(mat.data(), rows, cols));\n",
    "        return mat_list_;\n",
    "    }\n",
    "\n",
    "public: \n",
    "    OneBlockMatrixWrap(jlcxx::ArrayRef<double, 2> mat, int_t rows, int_t cols)\n",
    "        : orig_mat_(mat),\n",
    "        eigen_mat_(init_eigen_mat(mat, rows, cols)),\n",
    "        mat_list_(init_mat_list(eigen_mat_, rows, cols)),\n",
    "        block_mat_(mat_list_),\n",
    "        dim_(block_mat_.rows(), block_mat_.cols())\n",
    "    {}\n",
    "\n",
    "    // GHOSTBASIL_STRONG_INLINE\n",
    "    const auto& internal() const { return block_mat_; }\n",
    "\n",
    "    // For export only\n",
    "    const Eigen::Array<size_t, 2, 1> dim_exp() const { return dim_; }\n",
    "};\n",
    "\n",
    "// adapted from https://github.com/JamesYang007/ghostbasil/blob/master/R/inst/include/rcpp_block_group_ghost_matrix.hpp#L7\n",
    "class BlockGroupGhostMatrixWrap\n",
    "{\n",
    "public:\n",
    "    using bmat_t = ghostbasil::BlockMatrix<Eigen::Map<Eigen::MatrixXd>>;\n",
    "\n",
    "private:\n",
    "    jlcxx::ArrayRef<double, 2> orig_mat_S_;\n",
    "    jlcxx::ArrayRef<double, 2> orig_mat_D_;\n",
    "    Eigen::MatrixXd eigen_mat_S_;\n",
    "    Eigen::MatrixXd eigen_mat_D_;\n",
    "    const Eigen::Map<Eigen::MatrixXd> orig_S_;\n",
    "    const OneBlockMatrixWrap orig_D_;\n",
    "    ghostbasil::BlockGroupGhostMatrix<Eigen::MatrixXd, bmat_t> gmat_;\n",
    "    const Eigen::Array<size_t, 2, 1> dim_;\n",
    "\n",
    "public:\n",
    "    BlockGroupGhostMatrixWrap(\n",
    "        jlcxx::ArrayRef<double, 2> S, // standard matrix from Julia\n",
    "        jlcxx::ArrayRef<double, 2> D, // this will be converted to a BlockMatrix\n",
    "        int_t m, // m is number of knockoffs\n",
    "        size_t rows, // size(D, 1)\n",
    "        size_t cols  // size(D, 2)\n",
    "    )\n",
    "        : orig_mat_S_(S),\n",
    "          orig_mat_D_(D),\n",
    "          eigen_mat_S_(init_eigen_mat(S, rows, cols)),\n",
    "          eigen_mat_D_(init_eigen_mat(D, rows, cols)),\n",
    "          orig_S_(Eigen::Map<Eigen::MatrixXd>(eigen_mat_S_.data(), rows, cols)),\n",
    "          orig_D_(orig_mat_D_, rows, cols),\n",
    "          gmat_(orig_S_, \n",
    "                orig_D_.internal(), \n",
    "                m + 1), // in ghostbasil, the original variables counts as 1 knockoff\n",
    "          dim_(gmat_.rows(), gmat_.cols())\n",
    "    {}\n",
    "\n",
    "    // GHOSTBASIL_STRONG_INLINE\n",
    "    const auto& internal() const { return gmat_; }\n",
    "\n",
    "    // For export only\n",
    "    const Eigen::Array<size_t, 2, 1> dim_exp() const { return dim_; }\n",
    "};\n",
    "\n",
    "// Same function as `basil__` at \n",
    "// https://github.com/JamesYang007/ghostbasil/blob/master/R/src/rcpp_basil.cpp#L88\n",
    "// Except: (a) this returns only the beta that corresponds to the last lambda value\n",
    "// and (b) there is a lot less \"checking\" (so its behavior is unpredictable\n",
    "// when user early terminates)\n",
    "template <class AType>\n",
    "std::vector<double> basil__(\n",
    "        const AType& A, \n",
    "        const Eigen::Map<Eigen::VectorXd> r,\n",
    "        double alpha,\n",
    "        const Eigen::Map<Eigen::VectorXd> penalty,\n",
    "        const Eigen::Map<Eigen::VectorXd> user_lmdas,\n",
    "        size_t max_n_lambdas,\n",
    "        size_t n_lambdas_iter,\n",
    "        bool use_strong_rule,\n",
    "        bool do_early_exit,\n",
    "        size_t delta_strong_size,\n",
    "        size_t max_strong_size,\n",
    "        size_t max_n_cds,\n",
    "        double thr,\n",
    "        double min_ratio,\n",
    "        size_t n_threads)\n",
    "{\n",
    "    using namespace ghostbasil::lasso;\n",
    "\n",
    "    std::vector<Eigen::SparseVector<double>> betas;\n",
    "    std::vector<double> lmdas;\n",
    "    std::vector<double> rsqs;\n",
    "\n",
    "    // slight optimization: reserve spaces ahead of time\n",
    "    const size_t capacity = std::max(\n",
    "        max_n_lambdas, static_cast<size_t>(user_lmdas.size())\n",
    "    );\n",
    "    betas.reserve(capacity);\n",
    "    lmdas.reserve(capacity);\n",
    "    rsqs.reserve(capacity);\n",
    "    std::string error;\n",
    "\n",
    "    try {\n",
    "        basil(\n",
    "                A, r, alpha, penalty, user_lmdas, max_n_lambdas, n_lambdas_iter,\n",
    "                use_strong_rule, do_early_exit, delta_strong_size, max_strong_size, max_n_cds, thr, \n",
    "                min_ratio, n_threads,\n",
    "                betas, lmdas, rsqs);\n",
    "    }\n",
    "    catch (const std::exception& e) {\n",
    "        error = e.what();\n",
    "    }\n",
    "\n",
    "    // return the beta corresponding to the last lambda value\n",
    "    Eigen::SparseVector<double> last_beta = betas.back();\n",
    "    std::vector<double> dense_last_beta(last_beta.size(), 0.0);\n",
    "    for (Eigen::SparseVector<double>::InnerIterator it(last_beta); it; ++it) {\n",
    "        dense_last_beta[it.index()] = it.value();\n",
    "    }\n",
    "    return dense_last_beta;\n",
    "}\n",
    "\n",
    "// Same as `basil_block_group_ghost__` at\n",
    "// https://github.com/JamesYang007/ghostbasil/blob/master/R/src/rcpp_basil.cpp#L291\n",
    "// But we don't create a `BlockGroupGhostMatrix` in Julia. Instead, we\n",
    "// pass `C` and `S` as Julia matrices into C++, convert `S` to a `BlockMatrix`\n",
    "// with a single block, convert `C` to a Eigen matrix, and then pass `C` and `S`\n",
    "// directly into `basil__`\n",
    "std::vector<double> basil_block_group_ghost__(\n",
    "        const jlcxx::ArrayRef<double, 2> C, // dense matrix\n",
    "        const jlcxx::ArrayRef<double, 2> S, // becomes a BlockMatrix\n",
    "        const jlcxx::ArrayRef<double, 1> r,\n",
    "        const jlcxx::ArrayRef<double, 1> user_lmdas,\n",
    "        int_t m, // number of knockoffs\n",
    "        size_t p, // dimension of S and C (both square matrices)\n",
    "        size_t max_n_lambdas,\n",
    "        size_t n_lambdas_iter,\n",
    "        bool use_strong_rule,\n",
    "        bool do_early_exit,\n",
    "        size_t delta_strong_size,\n",
    "        size_t max_strong_size,\n",
    "        size_t max_n_cds,\n",
    "        double thr,\n",
    "        double min_ratio,\n",
    "        size_t n_threads)\n",
    "{\n",
    "    // convert C and S to instance of BlockGroupGhostMatrix\n",
    "    auto gmw = BlockGroupGhostMatrixWrap(C, S, m, p, p);\n",
    "    const auto& gm = gmw.internal();\n",
    "\n",
    "    // default alpha = 1.0 and penalty = vector of 1s\n",
    "    double alpha = 1.0;\n",
    "    Eigen::VectorXd ones = Eigen::VectorXd::Ones((m+1) * p);\n",
    "    Eigen::Map<Eigen::VectorXd> penalty(ones.data(), ones.size());\n",
    "\n",
    "    // convert r and user_lmdas to Eigen::Map<Eigen::VectorXd>\n",
    "    Eigen::VectorXd lmdas = init_eigen_vec(user_lmdas);\n",
    "    Eigen::VectorXd r1 = init_eigen_vec(r);\n",
    "    Eigen::Map<Eigen::VectorXd> lambdas(lmdas.data(), lmdas.size());\n",
    "    Eigen::Map<Eigen::VectorXd> r2(r1.data(), r1.size());\n",
    "\n",
    "    std::vector<double> result = basil__(\n",
    "            gm, r2, alpha, penalty, lambdas, max_n_lambdas,\n",
    "            n_lambdas_iter, use_strong_rule, do_early_exit, delta_strong_size,\n",
    "            max_strong_size, max_n_cds, thr, min_ratio, n_threads);\n",
    "\n",
    "    return result;\n",
    "}\n",
    "\n",
    "JLCXX_MODULE define_julia_module(jlcxx::Module& mod)\n",
    "{\n",
    "    mod.method(\"block_group_ghostbasil\", &basil_block_group_ghost__);\n",
    "}\n",
    "```\n",
    "\n",
    "### 2: Create `/home/users/bbchu/ghostbasil/julia/CMakeLists.txt`:\n",
    "\n",
    "```\n",
    "project(ghostbasil)\n",
    "\n",
    "cmake_minimum_required(VERSION 3.5)\n",
    "set(CMAKE_MACOSX_RPATH 1)\n",
    "set(CMAKE_LIBRARY_OUTPUT_DIRECTORY \"${CMAKE_BINARY_DIR}/lib\")\n",
    "\n",
    "find_package(JlCxx REQUIRED)\n",
    "find_package(Eigen3 3.3 REQUIRED NO_MODULE)\n",
    "include_directories(${CMAKE_CURRENT_SOURCE_DIR}/../ghostbasil/include)\n",
    "\n",
    "add_library(ghostbasil_wrap SHARED ghostbasil_wrap.cpp)\n",
    "target_link_libraries(ghostbasil_wrap JlCxx::cxxwrap_julia Eigen3::Eigen)\n",
    "install(TARGETS ghostbasil_wrap\n",
    "  LIBRARY DESTINATION lib\n",
    "  ARCHIVE DESTINATION lib\n",
    "  RUNTIME DESTINATION lib)\n",
    "```\n",
    "\n",
    "### 3. Build the shared library (`.io`) file at `/home/users/bbchu/ghostbasil/julia/build`\n",
    "\n",
    "```\n",
    "mkdir build && cd build\n",
    "cmake \\\n",
    "    -DCMAKE_BUILD_TYPE=Release \\\n",
    "    -DCMAKE_INSTALL_PREFIX=/home/groups/sabatti/.julia/artifacts/d25a86126e4d79572040fbf3f1fcda158a703a4a \\\n",
    "    -DEigen3_DIR=/share/software/user/open/eigen/3.4.0/share/eigen3/cmake \\\n",
    "    ../\n",
    "cmake --build . --config Release\n",
    "```\n",
    "\n",
    "### 4. Call from Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff4fc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all(isapprox.(C2, Ci, atol = 5.0e-7)) = true\n",
      "all(isapprox.(S2, Si_scaled, atol = 5.0e-7)) = true\n",
      "all(isapprox.(Adiag, Adiag2, atol = 5.0e-7)) = true\n",
      "all(isapprox.(Aoffdiag, Aoffdiag2, atol = 5.0e-7)) = true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mRCall.jl: Loading required package: Matrix\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ RCall /home/groups/sabatti/.julia/packages/RCall/aK5sD/src/io.jl:172\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count(!iszero, beta_i_true) = 14\n",
      "count(!iszero, beta_i) = 14\n",
      "all(beta_i_true .≈ beta_i) = true\n"
     ]
    }
   ],
   "source": [
    "# ml cmake/3.11.1 julia/1.8.4 eigen/3.4.0 R/4.0.2 gcc/7.1.0\n",
    "\n",
    "using DelimitedFiles\n",
    "using RCall\n",
    "\n",
    "# read first 4 args for ghostbasil\n",
    "datadir = \"/home/users/bbchu/ghostbasil/data\"\n",
    "Ci = readdlm(joinpath(datadir, \"Ci.txt\"))\n",
    "Si_scaled = readdlm(joinpath(datadir, \"Si_scaled.txt\"))\n",
    "r = readdlm(joinpath(datadir, \"r.txt\")) |> vec\n",
    "lambda_path = readdlm(joinpath(datadir, \"lambda_path.txt\")) |> vec\n",
    "Adiag = Ci + Si_scaled\n",
    "Aoffdiag = Ci\n",
    "\n",
    "# other arguments\n",
    "m = 5\n",
    "p = size(Ci, 1)\n",
    "max_n_lambdas = 100\n",
    "lambdas_iter = 5\n",
    "use_strong_rule = false\n",
    "do_early_exit = true\n",
    "delta_strong_size = 500\n",
    "max_strong_size = (m+1)*size(Ci, 1)\n",
    "max_n_cds = 100000\n",
    "thr = 1e-7\n",
    "min_ratio = 1e-2\n",
    "n_threads = 1\n",
    "\n",
    "# now start calling C++ routine\n",
    "module ghostbasil\n",
    "    using CxxWrap\n",
    "\n",
    "    @wrapmodule(() -> \"/home/users/bbchu/ghostbasil/julia/build/lib/libghostbasil_wrap\")\n",
    "\n",
    "    function __init__()\n",
    "        @initcxx\n",
    "    end\n",
    "\n",
    "    function block_group_ghostbasil(\n",
    "        Ci::Matrix{Float64}, \n",
    "        Si_scaled::Matrix{Float64}, \n",
    "        r::Vector{Float64}, \n",
    "        lambda_path::Vector{Float64};\n",
    "        m::Int = 5,\n",
    "        max_n_lambdas::Int = 100,\n",
    "        lambdas_iter::Int = 5,\n",
    "        use_strong_rule::Bool = false,\n",
    "        do_early_exit::Bool = true,\n",
    "        delta_strong_size::Int = 500,\n",
    "        max_strong_size::Int = (m+1)*size(Ci, 1),\n",
    "        max_n_cds::Int = 100000,\n",
    "        thr::Float64 = 1e-7,\n",
    "        min_ratio::Float64 = 1e-2,\n",
    "        n_threads::Int = 1,\n",
    "        )\n",
    "        # check for errors\n",
    "        p = size(Ci, 1)\n",
    "        size(Ci) == size(Si_scaled) || error(\"Expected size(Ci) == size(Si_scaled)\")\n",
    "        length(r) == (m+1)*p || error(\"Expected length(r) == $((m+1)*p)\")\n",
    "        issorted(lambda_path, rev=true) || \n",
    "            error(\"lambda_path should be sorted from largest to smallest\")\n",
    "        isapprox(Ci, Ci', atol=1e-8) || error(\"Ci is not symmetric\")\n",
    "        isapprox(Si_scaled, Si_scaled', atol=1e-8) || \n",
    "            error(\"Si_scaled is not symmetric\")\n",
    "        (m > 0) && (max_n_lambdas > 0) && (lambdas_iter > 0) && \n",
    "            (max_n_cds > 0) && (thr > 0) && (min_ratio > 0) || \n",
    "            error(\"Expected m, max_n_lambdas, lambdas_iter, max_n_cds, thr, min_ratio all to be > 0\")\n",
    "        \n",
    "        return block_group_ghostbasil(Ci, Si_scaled, r, lambda_path, \n",
    "            m, p, max_n_lambdas, lambdas_iter, use_strong_rule, do_early_exit, \n",
    "            delta_strong_size, max_strong_size, max_n_cds, thr, min_ratio, n_threads)\n",
    "    end\n",
    "\n",
    "    export block_group_ghostbasil\n",
    "end\n",
    "\n",
    "# julia wrapper of ghostbasil\n",
    "# beta_i = ghostbasil.block_group_ghostbasil(Ci, Si_scaled, r, lambda_path, \n",
    "#     m, p, max_n_lambdas, lambdas_iter, use_strong_rule, do_early_exit, \n",
    "#     delta_strong_size, max_strong_size, max_n_cds, thr, min_ratio, n_threads)\n",
    "@time beta_i = ghostbasil.block_group_ghostbasil(Ci, Si_scaled, r, lambda_path)\n",
    "\n",
    "# import data in C++ before running basil__ (eigen matrix, BlockMatrix, and BlockGroupGhostMatrix)\n",
    "C2 = readdlm(joinpath(datadir, \"C2.txt\"), Float64)\n",
    "S2 = readdlm(joinpath(datadir, \"S2.txt\"), Float64)\n",
    "A2 = readdlm(joinpath(datadir, \"A2.txt\"), Float64)\n",
    "Adiag2 = A2[1:p, 1:p]\n",
    "Aoffdiag2 = A2[p+1:2p, 1:p]\n",
    "@show all(isapprox.(C2, Ci, atol=5e-7))\n",
    "@show all(isapprox.(S2, Si_scaled, atol=5e-7))\n",
    "@show all(isapprox.(Adiag, Adiag2, atol=5e-7))\n",
    "@show all(isapprox.(Aoffdiag, Aoffdiag2, atol=5e-7))\n",
    "\n",
    "# check answer\n",
    "ncores = 1\n",
    "A_scaling_factor = 0.01\n",
    "@rput Ci Si_scaled r m ncores A_scaling_factor lambda_path\n",
    "R\"\"\"\n",
    "library(ghostbasil)\n",
    "\n",
    "# make S into a block matrix with a single block\n",
    "Si_scaled <- BlockMatrix(list(Si_scaled))\n",
    "# form Bi\n",
    "Bi <- BlockGroupGhostMatrix(Ci, Si_scaled, m+1)\n",
    "# run ghostbasil on one specific lambda\n",
    "result <- ghostbasil(Bi, r, delta.strong.size=500, \n",
    "    max.strong.size = nrow(Bi), n.threads=ncores, \n",
    "    user.lambdas=lambda_path, use.strong.rule=F)\n",
    "beta_i_true <- result$betas[,ncol(result$betas)]\n",
    "0.0 # prevents printing beta_i_true\n",
    "\"\"\"\n",
    "@rget beta_i_true;\n",
    "@show count(!iszero, beta_i_true);\n",
    "@show count(!iszero, beta_i);\n",
    "@show all(beta_i_true .≈ beta_i);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d96d286",
   "metadata": {},
   "source": [
    "Below is code for generating test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml cmake/3.11.1 gcc/12.1.0 julia/1.8.4 eigen/3.4.0 R/4.0.2\n",
    "\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Random\n",
    "using Distributions\n",
    "using JLD2\n",
    "using Knockoffs\n",
    "using LinearAlgebra\n",
    "using DelimitedFiles\n",
    "\n",
    "function pval2zscore(pvals::AbstractVector{T}, beta::AbstractVector{T}) where T\n",
    "    length(pvals) == length(beta) || \n",
    "        error(\"pval2zscore: pvals and beta should have the same length\")\n",
    "    return zscore.(pvals, beta)\n",
    "end\n",
    "zscore(p::T, beta::T) where T = sign(beta) * quantile(Normal(), p/2)\n",
    "\n",
    "function read_phenotype_zscores(filepath::String)\n",
    "    info = CSV.read(filepath, DataFrame)\n",
    "    # reach chr,pos, and ref/alt alleles\n",
    "    chr = info[!, \"chr\"]\n",
    "    pos = info[!, \"snp_pos\"]\n",
    "    effect_allele = info[!, \"effect_allele\"] |> Vector{String}\n",
    "    non_effect_allele = info[!, \"non_effect_allele\"] |> Vector{String}\n",
    "    # read Z scores\n",
    "    columnnames = names(info)\n",
    "    if \"pvalue\" in columnnames && \"beta\" in columnnames\n",
    "        pvals = info[!, \"pvalue\"]\n",
    "        betas = info[!, \"beta\"]\n",
    "        z = pval2zscore(pvals, betas)\n",
    "    elseif \"or\" in columnnames && \"se\" in columnnames\n",
    "        odds_ratio = info[!, \"or\"]\n",
    "        se = info[!, \"se\"]\n",
    "        z = log.(odds_ratio) ./ se\n",
    "    else\n",
    "        error(\"can't read phenotype Z scores! Column name = $names\")\n",
    "    end\n",
    "    # remove NaN/Inf\n",
    "    idx = findall(x -> !isnan(x) && !isinf(x), z)\n",
    "    return z[idx], chr[idx], pos[idx], effect_allele[idx], non_effect_allele[idx]\n",
    "end\n",
    "\n",
    "# for testing\n",
    "knockoff_dir = \"/oak/stanford/groups/zihuai/pan_ukb_group_knockoffs/EUR\"\n",
    "gwas_dir = \"/oak/stanford/groups/zihuai/GWAS_Summary_Gloudemans\"\n",
    "master_df = CSV.read(joinpath(gwas_dir, \"includedstudy_info_100000_Ancestry.txt\"), DataFrame)\n",
    "hg_build = 38\n",
    "filepath = master_df[93, \"filepath\"]\n",
    "studyname = master_df[93, \"studyname\"]\n",
    "samplesize = master_df[93, \"samplesize\"]\n",
    "seed = 2023\n",
    "\n",
    "# read z scores and other necessary infos\n",
    "z, chr, pos, effect_allele, non_effect_allele = read_phenotype_zscores(filepath)\n",
    "\n",
    "# read 1 region Sigma and S\n",
    "c = 22\n",
    "m = 5\n",
    "files = readdir(joinpath(knockoff_dir, \"chr$c\"))\n",
    "chr_idx = findall(x -> x == c, chr)\n",
    "GWAS_pos = pos[chr_idx]\n",
    "GWAS_ea = effect_allele[chr_idx]\n",
    "GWAS_nea = non_effect_allele[chr_idx]\n",
    "zscores = z[chr_idx]\n",
    "f = files[44]\n",
    "fname = f[4:end-3]\n",
    "\n",
    "# read 1 region of knockoff result \n",
    "t1 = @elapsed begin\n",
    "    # read knockoff results\n",
    "    result = JLD2.load(joinpath(knockoff_dir, \"chr$c\", f))\n",
    "    Sigma_info = CSV.read(joinpath(knockoff_dir, \"chr$(c)\", \"Info_$fname.csv\"), DataFrame)\n",
    "    # map reference LD panel to GWAS Z-scores by position\n",
    "    LD_pos = Sigma_info[!, \"pos_hg$(hg_build)\"]\n",
    "    shared_snps = intersect(LD_pos, GWAS_pos)\n",
    "    # delete SNPs if ref/alt don't match\n",
    "    remove_idx = Int[]\n",
    "    for (i, snp) in enumerate(shared_snps)\n",
    "        GWAS_idx = findfirst(x -> x == snp, GWAS_pos)\n",
    "        LD_idx = findfirst(x -> x == snp, LD_pos)\n",
    "        ref_match_ea = Sigma_info[LD_idx, \"ref\"] == GWAS_ea[GWAS_idx]\n",
    "        alt_match_nea = Sigma_info[LD_idx, \"alt\"] == GWAS_nea[GWAS_idx]\n",
    "        ref_match_nea = Sigma_info[LD_idx, \"ref\"] == GWAS_nea[GWAS_idx]\n",
    "        alt_match_ea = Sigma_info[LD_idx, \"alt\"] == GWAS_ea[GWAS_idx]\n",
    "        if ref_match_ea && alt_match_nea \n",
    "            continue\n",
    "        elseif ref_match_nea && alt_match_ea\n",
    "            zscores[GWAS_idx] *= -1\n",
    "        else # SNP cannot get matched to LD panel\n",
    "            push!(remove_idx, i)\n",
    "        end\n",
    "    end\n",
    "    deleteat!(shared_snps, unique!(remove_idx))\n",
    "    # save matching snps info\n",
    "    LD_keep_idx = indexin(shared_snps, LD_pos)\n",
    "    GWAS_keep_idx = indexin(shared_snps, GWAS_pos)\n",
    "end\n",
    "\n",
    "# generate knockoffs for z scores\n",
    "t2 = @elapsed begin\n",
    "    # use original Sigma and D (S matrix for rep+nonrep variables) for pseudo-validation\n",
    "    Si = result[\"D\"][LD_keep_idx, LD_keep_idx]\n",
    "    Σi = result[\"Sigma\"][LD_keep_idx, LD_keep_idx]\n",
    "    zscore_tmp = @view(zscores[GWAS_keep_idx])\n",
    "    # sample ghost knockoffs knockoffs\n",
    "    Zko_train = Knockoffs.sample_mvn_efficient(Σi, Si, m + 1)\n",
    "    Σi_inv = inv(Symmetric(Σi))\n",
    "    Zko = ghost_knockoffs(zscore_tmp, Si, Σi_inv, m=m)\n",
    "end\n",
    "\n",
    "# first 3 ghostbasil input\n",
    "N = samplesize\n",
    "Ci = Σi - Si\n",
    "Si_scaled = Si + 0.01*I\n",
    "Zscores_store = vcat(zscore_tmp, Zko)\n",
    "r = Zscores_store ./ sqrt(N)\n",
    "\n",
    "\n",
    "# lambda seq\n",
    "lambdamax = maximum(abs, z) / sqrt(N)\n",
    "lambdamin = 0.0001lambdamax\n",
    "lambda_path = exp.(range(log(lambdamin), log(lambdamax), length=100)) |> reverse!\n",
    "nsnps = 600000\n",
    "lambda = 0.6 * maximum(abs, randn((m+1)*nsnps)) / sqrt(N)\n",
    "lambda_path = lambda_path[findall(x -> x > lambda, lambda_path)]\n",
    "\n",
    "\n",
    "# save these for faster reading later\n",
    "datadir = \"/home/users/bbchu/ghostbasil/data\"\n",
    "writedlm(joinpath(datadir, \"Ci.txt\"), Ci)\n",
    "writedlm(joinpath(datadir, \"Si_scaled.txt\"), Si_scaled)\n",
    "writedlm(joinpath(datadir, \"r.txt\"), r)\n",
    "writedlm(joinpath(datadir, \"lambda_path.txt\"), lambda_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e334ff79",
   "metadata": {},
   "source": [
    "# Make jll package via BinaryBuilder\n",
    "\n",
    "```julia\n",
    "using BinaryBuilder\n",
    "state = BinaryBuilder.run_wizard()\n",
    "```\n",
    "\n",
    "1. Must run this on mac (rather than on Sherlock/Hoffman2 cluster), see [this issue](https://github.com/JuliaPackaging/BinaryBuilder.jl/issues/1306)\n",
    "2. We only build for linux and Mac, since ghostbasil doesn't currently build on windows\n",
    "3. Source code\n",
    "    + URL: https://github.com/biona001/ghostbasil\n",
    "    + commit: 5a7121542d39ac4439b366d0223cd117f4211681\n",
    "4. When asked whether there are additional \"binary dependencies\", my understanding is that we at least need Julia itself and the libcxxwrap library to enable interfacing with C++. Since ghosbasil also requires `Eigen` package, we actually have 3 binary dependencies:\n",
    "    + libcxxwrap_julia_jll\n",
    "    + Eigen_jll\n",
    "    + libjulia_jll\n",
    "5. When asked whether to customize the set of compilers, we used\n",
    "    + GCC: 7.1.0 (note: according to [BinaryBuilder docs](https://github.com/JuliaPackaging/Yggdrasil/blob/0d38df8bc8ad10cff5fba1c19a5932a84286fcd2/CONTRIBUTING.md#compatibility-tips), we should use oldest possible gcc)\n",
    "    + LLVM: 16.0.6\n",
    "6. build script:\n",
    "\n",
    "```\n",
    "mkdir ghostbasil/julia/build\n",
    "cd ghostbasil/julia/build\n",
    "cmake -DJulia_PREFIX=$prefix -DCMAKE_INSTALL_PREFIX=$prefix -DCMAKE_FIND_ROOT_PATH=$prefix -DCMAKE_TOOLCHAIN_FILE=${CMAKE_TARGET_TOOLCHAIN} -DEigen3_DIR=$prefix/share/eigen3/cmake -DCMAKE_BUILD_TYPE=Release ..\n",
    "make\n",
    "make install\n",
    "install_license $WORKSPACE/srcdir/ghostbasil/R/LICENSE.md\n",
    "```\n",
    "\n",
    "7. Before opening a PR, lets first test the `build_tarballs.jl` by seeing if we can [build `jll` package onto github](https://docs.binarybuilder.org/stable/FAQ/#Can-I-publish-a-JLL-package-locally-without-going-through-Yggdrasil?):\n",
    "```\n",
    "julia build_tarballs.jl x86_64-linux-gnu --debug --verbose --deploy=\"biona001/ghostbasil_jll.jl\"\n",
    "```\n",
    "\n",
    "8. Step 7 should have generated `.julia/dev/ghostbasil_jll` package, and a bunch of artifact files under `.julia/artifacts/<GIT_TREE_HASH_OF_YOUR_ARTIFACT_THAT_YOU_CAN_FIND_IN_YOUR_ARTIFACTS.TOML_FILE>`. I copied them onto Sherlock and lets see if it works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781405a3",
   "metadata": {},
   "source": [
    "# Write `ghostbasil.jl` package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5188dc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mRCall.jl: Loading required package: Matrix\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ RCall /home/groups/sabatti/.julia/packages/RCall/gOwEW/src/io.jl:172\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count(!iszero, beta_i_true) = 14\n",
      "count(!iszero, beta_i) = 14\n",
      "all(beta_i_true .≈ beta_i) = true\n"
     ]
    }
   ],
   "source": [
    "# ml cmake/3.11.1 gcc/12.1.0 julia/1.8.4 eigen/3.4.0 R/4.0.2\n",
    "\n",
    "using ghostbasil\n",
    "using DelimitedFiles\n",
    "using RCall\n",
    "\n",
    "# read first 4 args for ghostbasil\n",
    "datadir = \"/home/users/bbchu/ghostbasil/data\"\n",
    "Ci = readdlm(joinpath(datadir, \"Ci.txt\"))\n",
    "Si_scaled = readdlm(joinpath(datadir, \"Si_scaled.txt\"))\n",
    "r = readdlm(joinpath(datadir, \"r.txt\")) |> vec\n",
    "lambda_path = readdlm(joinpath(datadir, \"lambda_path.txt\")) |> vec\n",
    "Adiag = Ci + Si_scaled\n",
    "Aoffdiag = Ci\n",
    "\n",
    "# julia wrapper of ghostbasil\n",
    "beta_i = block_group_ghostbasil(Ci, Si_scaled, r, lambda_path)\n",
    "\n",
    "# check answer\n",
    "ncores = 1\n",
    "A_scaling_factor = 0.01\n",
    "m = 5\n",
    "@rput Ci Si_scaled r m ncores A_scaling_factor lambda_path\n",
    "R\"\"\"\n",
    "library(ghostbasil)\n",
    "\n",
    "# make S into a block matrix with a single block\n",
    "Si_scaled <- BlockMatrix(list(Si_scaled))\n",
    "# form Bi\n",
    "Bi <- BlockGroupGhostMatrix(Ci, Si_scaled, m+1)\n",
    "# run ghostbasil on one specific lambda\n",
    "result <- ghostbasil(Bi, r, delta.strong.size=500, \n",
    "    max.strong.size = nrow(Bi), n.threads=ncores, \n",
    "    user.lambdas=lambda_path, use.strong.rule=F)\n",
    "beta_i_true <- result$betas[,ncol(result$betas)]\n",
    "0.0 # prevents printing beta_i_true\n",
    "\"\"\"\n",
    "@rget beta_i_true;\n",
    "@show count(!iszero, beta_i_true);\n",
    "@show count(!iszero, beta_i);\n",
    "@show all(beta_i_true .≈ beta_i);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479b71c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0005451576807477974, -0.0002947665358369119, -0.014810108231841996, -0.00043238505905553924, -0.006856782960094195, 0.0016850133196618926, -0.00019274743491070077, -0.0003841629682186662, -0.0005758897376517483, -0.0016095272344540995, 0.0020146776266541312, -0.001666736964454875, 0.0004269118551173737, 0.00010746291189108347]\n"
     ]
    }
   ],
   "source": [
    "beta_i[findall(!iszero, beta_i)] |> println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd67c222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0005451576807477974, -0.0002947665358369119, -0.014810108231841996, -0.00043238505905553924, -0.006856782960094195, 0.0016850133196618926, -0.00019274743491070077, -0.0003841629682186662, -0.0005758897376517483, -0.0016095272344540995, 0.0020146776266541312, -0.001666736964454875, 0.0004269118551173737, 0.00010746291189108347]\n"
     ]
    }
   ],
   "source": [
    "beta_i_true[findall(!iszero, beta_i_true)] |> println"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5395f5",
   "metadata": {},
   "source": [
    "## PackageCompiler.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071e336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
